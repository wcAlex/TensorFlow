{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Character prediction using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in /usr/local/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: tensorflow in /usr/local/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: six>=1.10.0 in /usr/local/lib/python2.7/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: numpy>=1.12.1 in /usr/local/lib/python2.7/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python2.7/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: mock>=2.0.0 in /usr/local/lib/python2.7/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: enum34>=1.1.6 in /usr/local/lib/python2.7/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: protobuf>=3.3.0 in /usr/local/lib/python2.7/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: wheel in /usr/local/lib/python2.7/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: werkzeug>=0.11.10 in /usr/local/lib/python2.7/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "Requirement already up-to-date: html5lib==0.9999999 in /usr/local/lib/python2.7/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "Requirement already up-to-date: futures>=3.1.1; python_version < \"3.2\" in /usr/local/lib/python2.7/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "Requirement already up-to-date: bleach==1.5.0 in /usr/local/lib/python2.7/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "Requirement already up-to-date: markdown>=2.6.8 in /usr/local/lib/python2.7/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow)\n",
      "Requirement already up-to-date: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow)\n",
      "Requirement already up-to-date: pbr>=0.11 in /usr/local/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow)\n",
      "Requirement already up-to-date: setuptools in /usr/local/lib/python2.7/site-packages (from protobuf>=3.3.0->tensorflow)\n",
      "Requirement already up-to-date: bs4 in /usr/local/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: beautifulsoup4 in /usr/local/lib/python2.7/site-packages (from bs4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.3\n",
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Download technical paper summaries\n",
    "\n",
    "* Papers are on machine learning, neural networks\n",
    "* The downloaded data is 100MB so will take a long time to write out\n",
    "* Roughly 100K papers with these categories and keywords present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = 'http://export.arxiv.org/api/query'\n",
    "CATEGORIES = [\n",
    "    'Machine Learning',\n",
    "    'Neural and Evolutionary Computing',\n",
    "    'Optimization'\n",
    "]\n",
    "KEYWORDS = [\n",
    "    'neural',\n",
    "    'network',\n",
    "    'deep'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_url(amount, offset):\n",
    "    categories = ' OR '.join('cat:' + x for x in CATEGORIES)\n",
    "    keywords = ' OR '.join('all:' + x for x in KEYWORDS)\n",
    "\n",
    "    url = BASE_PATH\n",
    "    url += '?search_query=(({}) AND ({}))'.format(categories, keywords)\n",
    "    url += '&max_results={}&offset={}'.format(amount, offset)\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://export.arxiv.org/api/query?search_query=((cat:Machine Learning OR cat:Neural and Evolutionary Computing OR cat:Optimization) AND (all:neural OR all:network OR all:deep))&max_results=0&offset=0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_url(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Beautiful soup and the *lxml* parser\n",
    "\n",
    "Very clear directions on what Beautiful Soup is and how to get it on your local machine\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "Install Beautiful Soup\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup\n",
    "\n",
    "Get the **lxml** parser\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_count():\n",
    "    url = build_url(0, 0)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    count = int(soup.find('opensearch:totalresults').string)\n",
    "    print(count, 'papers found')\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107977 papers found\n"
     ]
    }
   ],
   "source": [
    "num_papers = get_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PAGE_SIZE = 100\n",
    "\n",
    "def fetch_page(amount, offset):\n",
    "    url = build_url(amount, offset)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    for entry in soup.findAll('entry'):\n",
    "        text = entry.find('summary').text\n",
    "        text = text.strip().replace('\\n', ' ')\n",
    "        yield text\n",
    "\n",
    "def fetch_all():\n",
    "    for offset in range(0, num_papers, PAGE_SIZE):\n",
    "        print('Fetch papers {}/{}'.format(offset + PAGE_SIZE, num_papers))\n",
    "        \n",
    "        for page in fetch_page(PAGE_SIZE, offset):\n",
    "            yield page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Huge amount of data\n",
    "\n",
    "This takes a while to run. Alternatively you can just download the **arxiv_abstracts.txt** from here: https://goo.gl/QoZH4Y and place it in your current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DOWNLOADED_FILENAME = 'arxiv_abstracts.txt'\n",
    "\n",
    "def download_data():\n",
    "    if not os.path.isfile(DOWNLOADED_FILENAME):\n",
    "        with open(DOWNLOADED_FILENAME, 'w') as file_:\n",
    "            for abstract in fetch_all():\n",
    "                file_.write(abstract + '\\n')\n",
    "    with open(DOWNLOADED_FILENAME) as file_:\n",
    "        data = file_.readlines()\n",
    "        \n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105965"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### The number of time steps used when we train our data\n",
    "\n",
    "All of the sentences in our abstracts are divided into windows of 50 characters. Our RNN will have 50 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 50\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VOCABULARY = \\\n",
    "        \" $%'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\" \\\n",
    "        \"\\\\^_abcdefghijklmnopqrstuvwxyz{|}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Assign a unique number to represent each character\n",
    "\n",
    "The number representation of the character is used as an index in the one-hot representation of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lookup = {x: i for i, x in enumerate(VOCABULARY)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('}', 82),\n",
       " ('P', 40),\n",
       " ('p', 69),\n",
       " ('{', 80),\n",
       " ('K', 35),\n",
       " ('Y', 49),\n",
       " ('n', 67),\n",
       " ('|', 81),\n",
       " ('1', 12),\n",
       " ('.', 9)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lookup = random.sample(lookup.items(), 10)\n",
    "sample_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### One-hot representation of each character\n",
    "\n",
    "* Every window of characters is of MAX_SEQUENCE_LENGTH (50)\n",
    "* Each character is represented in one-hot notation\n",
    "* Every feature vector has length equal to number of characters in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def one_hot(batch, sequence_length = MAX_SEQUENCE_LENGTH):\n",
    "    one_hot_batch = np.zeros((len(batch), sequence_length, len(VOCABULARY)))\n",
    "\n",
    "    # Iterate through every line of text in a batch\n",
    "    for index, line in enumerate(batch):\n",
    "        line = [x for x in line if x in lookup]\n",
    "        assert 2 <= len(line) <= MAX_SEQUENCE_LENGTH\n",
    "        \n",
    "        # Iterate through every character in a line\n",
    "        for offset, character in enumerate(line):\n",
    "            # Code is the index of the character in the vocabulary\n",
    "            code = lookup[character]\n",
    " \n",
    "            one_hot_batch[index, offset, code] = 1\n",
    "    \n",
    "    return one_hot_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Sliding window over every line\n",
    "\n",
    "* Generate batches of characters for training data\n",
    "* Start the sliding window at index 0 for every line\n",
    "* Slide the window over till the last character in the line is included\n",
    "* Have a stride of MAX_SEQUENCE_LENGTH // 2 for every window move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def next_batch():\n",
    "    windows = []\n",
    "    for line in data:\n",
    "        for i in range(0, len(line) - MAX_SEQUENCE_LENGTH + 1, MAX_SEQUENCE_LENGTH // 2):\n",
    "            windows.append(line[i: i + MAX_SEQUENCE_LENGTH])\n",
    "\n",
    "    # All text at this point are in the form of windows of MAX_SEQUENCE_LENGTH characters\n",
    "    assert all(len(x) == len(windows[0]) for x in windows)\n",
    "\n",
    "#     print('Number of windows: ', len(windows))\n",
    "#     print('Length of one window: ', len(windows[0]))\n",
    "\n",
    "    while True:\n",
    "        random.shuffle(windows)\n",
    "        for i in range(0, len(windows), BATCH_SIZE):\n",
    "            batch = windows[i: i + BATCH_SIZE]\n",
    "            yield one_hot(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of windows:  3916908\n",
      "Length of one window:  50\n",
      "(100, 50, 83)\n"
     ]
    }
   ],
   "source": [
    "test_batch = None\n",
    "for batch in next_batch():\n",
    "    test_batch = batch\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Set up the inputs to the RNN\n",
    "\n",
    "* One batch of MAX_SEQUENCE_LENGTH characters is the input sequence\n",
    "* The training X and the target y should be constructed from this input\n",
    "* St is the input and St+1 is the target\n",
    "* Slice the sequence to get X, **X has the last frame cut away**\n",
    "* Slice the sequence to get the corresponding y, **y has the first frame cut away**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sequence = tf.placeholder(tf.float32, [None, MAX_SEQUENCE_LENGTH, len(VOCABULARY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.slice(sequence, (0, 0, 0), (-1, MAX_SEQUENCE_LENGTH - 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = tf.slice(sequence, (0, 1, 0), (-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(49), Dimension(83)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(49), Dimension(83)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Sequence length calculation\n",
    "\n",
    "The sequence length here will **be the same for all our inputs** because they have been generated using the sliding window.\n",
    "\n",
    "We've sliced away either the first frame (for the labels) or the last frame (for the input) so the sequence length will be *MAX_SEQUENCE_LENGTH - 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_mask(target):\n",
    "    mask = tf.reduce_max(tf.abs(target), reduction_indices=2)\n",
    "    return mask\n",
    "\n",
    "def get_sequence_length(target):\n",
    "    mask = get_mask(target)\n",
    "    sequence_length = tf.reduce_sum(mask, reduction_indices=1)\n",
    "    \n",
    "    return sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### RNN for training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_neurons = 200\n",
    "cell_layers = 2\n",
    "\n",
    "num_steps = MAX_SEQUENCE_LENGTH - 1\n",
    "num_classes = len(VOCABULARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sequence_length = get_sequence_length(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### MultiRNNCell\n",
    "\n",
    "Used to stack multiple RNN cells and have them behave as a single cell\n",
    "\n",
    "**MultiRNNCell([lstm] * 5)** will build a 5 layer LSTM stack where each layer shares the same parameters\n",
    "\n",
    "**MultiRNNCell([LSTMCell(...) for _ in range(5)])** will give 5 layers where each layer has its own parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(data, num_steps, sequence_length, initial=None):\n",
    "    cell = tf.nn.rnn_cell.GRUCell(num_neurons)\n",
    "\n",
    "    multi_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "        [tf.nn.rnn_cell.GRUCell(num_neurons) for _ in range(cell_layers)])\n",
    "\n",
    "    output, state = tf.nn.dynamic_rnn(\n",
    "        inputs=data,\n",
    "        cell=multi_cell,\n",
    "        dtype=tf.float32,\n",
    "        initial_state=initial,\n",
    "        sequence_length=sequence_length)\n",
    "\n",
    "    # Shared softmax layer across all RNN cells\n",
    "    weight = tf.Variable(tf.truncated_normal([num_neurons, num_classes], stddev=0.01))\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[num_classes]))\n",
    "\n",
    "    flattened_output = tf.reshape(output, [-1, num_neurons])\n",
    "\n",
    "    prediction = tf.nn.softmax(tf.matmul(flattened_output, weight) + bias)\n",
    "    prediction = tf.reshape(prediction, [-1, num_steps, num_classes])\n",
    "\n",
    "    return prediction, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Prediction and the last recurrent activation\n",
    "\n",
    "In the training phase of this RNN we only use the *prediction* output. The second output, the *last recurrent activation* is ignored. In the prediction phase later on, we will use the last recurrent activation to generate sequences more effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prediction, _ = build_rnn(X, num_steps, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Cost calculation\n",
    "\n",
    "Basic cross entropy loss calculated manually on our prediction output from the RNN. This is used in place of the *tf.nn.softmax_cross_entropy_with_logits* library function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mask = get_mask(y)\n",
    "\n",
    "prediction = tf.clip_by_value(prediction, 1e-10, 1.0)\n",
    "\n",
    "cross_entropy = y * tf.log(prediction)\n",
    "cross_entropy = -tf.reduce_sum(cross_entropy, reduction_indices=2)\n",
    "\n",
    "cross_entropy *= mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "length = tf.reduce_sum(sequence_length, 0)\n",
    "\n",
    "cross_entropy = tf.reduce_sum(cross_entropy, reduction_indices=1) / length\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Calculate the log probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logprob = tf.multiply(prediction, y)\n",
    "logprob = tf.reduce_max(logprob, reduction_indices=2)\n",
    "logprob = tf.log(tf.clip_by_value(logprob, 1e-10, 1.0)) / tf.log(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logprob *= mask\n",
    "\n",
    "length = tf.reduce_sum(sequence_length, 0)\n",
    "\n",
    "logprob = tf.reduce_sum(logprob, reduction_indices=1) / length\n",
    "logprob = tf.reduce_mean(logprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(0.002)\n",
    "\n",
    "gradient = optimizer.compute_gradients(cross_entropy)\n",
    "\n",
    "optimize = optimizer.apply_gradients(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "epoch_size = 50\n",
    "\n",
    "logprob_evals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './sample_checkpoint_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 perplexity 1.0452\n",
      "Epoch  1 perplexity 1.0452\n",
      "Epoch  2 perplexity 1.0450\n",
      "Epoch  3 perplexity 1.0384\n",
      "Epoch  4 perplexity 1.0318\n",
      "Epoch  5 perplexity 1.0314\n",
      "Epoch  6 perplexity 1.0312\n",
      "Epoch  7 perplexity 1.0312\n",
      "Epoch  8 perplexity 1.0312\n",
      "Epoch  9 perplexity 1.0311\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for _ in range(epoch_size):\n",
    "            batch = next(next_batch())\n",
    "            \n",
    "            logprob_eval, _ = sess.run((logprob, optimize), {sequence: batch})\n",
    "            \n",
    "            logprob_evals.append(logprob_eval)\n",
    "            \n",
    "        saver.save(sess, os.path.join(checkpoint_dir, 'char_pred'), epoch)    \n",
    "        \n",
    "        perplexity = 2 ** -(sum(logprob_evals[-epoch_size:]) /\n",
    "                            epoch_size)\n",
    "        print('Epoch {:2d} perplexity {:5.4f}'.format(epoch, perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
